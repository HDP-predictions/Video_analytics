{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 1\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "#tf.random.set_seed(seed_value)\n",
    "# for later versions: \n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "#session_conf = tf.ConfigProto()\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "#K.set_session(sess)\n",
    "# for later versions:\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# tf.compat.v1.keras.backend.set_session(sess)\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import LSTM\n",
    "#import numpy as np\n",
    "import glob\n",
    "from imageio import imread\n",
    "from skimage.transform import resize as imresize\n",
    "from keras.layers import LeakyReLU\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "seq = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2,2054,2060,2061,2065,2066,2067,2068) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train_zero_padded.csv')\n",
    "val = pd.read_csv('validation_zero_padded_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.drop('labels',axis=1,inplace=True)\n",
    "val.drop('t',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'title_x', '0', '1', '2', '3', '4', '5',\n",
       "       '6',\n",
       "       ...\n",
       "       'tags', 'UHID', 'Video (Title)',\n",
       "       'Total Duration of video file (min.sec)', 'From (min.sec)',\n",
       "       'To (min.sec)', 'Procedure or manipulation (Name)', 'Label', 'title_y',\n",
       "       'time'],\n",
       "      dtype='object', length=2068)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'title', '0', '1', '2', '3', '4', '5', '6', '7',\n",
       "       ...\n",
       "       '2047', 'diaper_change', 'feeding', 'patting', 'uhid', 'Total_frames',\n",
       "       'frame_number', 'series', 'tags', 'labels'],\n",
       "      dtype='object', length=2059)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(LSTM(256,dropout=0.2,input_shape=(None,2048)))\n",
    "model.add(LSTM(512,return_sequences=True,activation='tanh',input_shape=(None,2048)))\n",
    "#model.add(activation='tanh')\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(LSTM(256,return_sequences=False))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es =   EarlyStopping(monitor='val_loss', patience=8, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "#train.drop('tags',axis=1,inplace=True)\n",
    "val.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "val.drop('Unnamed: 0.1',axis=1,inplace=True)\n",
    "val.drop('tags',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = train['uhid'].unique()\n",
    "ids_val = val['uhid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.DataFrame()\n",
    "X = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ids:\n",
    "    patient = train[train['uhid']==i]\n",
    "    total_frames = patient['Total_frames'].unique()\n",
    "    for j in total_frames:\n",
    "        x = patient[patient['Total_frames']==j]\n",
    "        x = x.sort_values(by=['series','frame_number'])             \n",
    "        x['diaper_change'].fillna(method='ffill',inplace=True)\n",
    "        x['feeding'].fillna(method='ffill',inplace=True)\n",
    "        x['patting'].fillna(method='ffill',inplace=True)\n",
    "        X = X.append(x,ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ids_val:\n",
    "    patient = val[val['uhid']==i]\n",
    "    total_frames = patient['Total_frames'].unique()\n",
    "    for j in total_frames:\n",
    "        x = patient[patient['Total_frames']==j]\n",
    "        x = x.sort_values(by=['series','frame_number'])             \n",
    "        x['diaper_change'].fillna(method='ffill',inplace=True)\n",
    "        x['feeding'].fillna(method='ffill',inplace=True)\n",
    "        x['patting'].fillna(method='ffill',inplace=True)\n",
    "        \n",
    "        X_val = X_val.append(x,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('title',axis=1,inplace=True)\n",
    "X.drop('uhid',axis=1,inplace=True)\n",
    "X.drop('Total_frames',axis=1,inplace=True)\n",
    "X.drop('frame_number',axis=1,inplace=True)\n",
    "X.drop('series',axis=1,inplace=True)\n",
    "X.drop('labels',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_val.drop('title_x',axis=1,inplace=True)\n",
    "X_val.drop('uhid',axis=1,inplace=True)\n",
    "X_val.drop('Total_frames',axis=1,inplace=True)\n",
    "X_val.drop('frame_number',axis=1,inplace=True)\n",
    "X_val.drop('series',axis=1,inplace=True)\n",
    "X_val.drop('title_y',axis=1,inplace=True)\n",
    "X_val.drop('To (min.sec)',axis=1,inplace=True)\n",
    "X_val.drop('Procedure or manipulation (Name)',axis=1,inplace=True)\n",
    "X_val.drop('From (min.sec)',axis=1,inplace=True)\n",
    "X_val.drop('Total Duration of video file (min.sec)',axis=1,inplace=True)\n",
    "X_val.drop('Video (Title)',axis=1,inplace=True)\n",
    "#X_val.drop('Total Duration of video file (min.sec)',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.drop('UHID',axis=1,inplace=True)\n",
    "X_val.drop('Label',axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.drop('time',axis=1,inplace=True)\n",
    "X_val.drop('title_x',axis=1,inplace=True)\n",
    "#X_val.drop('Total Duration of video file (min.sec)',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>diaper_change</th>\n",
       "      <th>feeding</th>\n",
       "      <th>patting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.128828</td>\n",
       "      <td>-0.016527</td>\n",
       "      <td>-0.235906</td>\n",
       "      <td>0.698256</td>\n",
       "      <td>0.543091</td>\n",
       "      <td>-0.188442</td>\n",
       "      <td>-1.163451</td>\n",
       "      <td>0.662182</td>\n",
       "      <td>0.054379</td>\n",
       "      <td>-0.649465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.626992</td>\n",
       "      <td>1.508141</td>\n",
       "      <td>-0.575721</td>\n",
       "      <td>0.488262</td>\n",
       "      <td>0.645725</td>\n",
       "      <td>-0.073558</td>\n",
       "      <td>0.912954</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.018054</td>\n",
       "      <td>0.201727</td>\n",
       "      <td>-0.318205</td>\n",
       "      <td>0.681947</td>\n",
       "      <td>0.933839</td>\n",
       "      <td>-1.113128</td>\n",
       "      <td>-0.237611</td>\n",
       "      <td>-0.608168</td>\n",
       "      <td>0.940666</td>\n",
       "      <td>-0.139904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670192</td>\n",
       "      <td>0.204470</td>\n",
       "      <td>-0.488212</td>\n",
       "      <td>-0.334271</td>\n",
       "      <td>0.508915</td>\n",
       "      <td>0.046070</td>\n",
       "      <td>0.630174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.818614</td>\n",
       "      <td>-0.363673</td>\n",
       "      <td>-0.230043</td>\n",
       "      <td>-0.020318</td>\n",
       "      <td>1.628263</td>\n",
       "      <td>-1.709915</td>\n",
       "      <td>0.289006</td>\n",
       "      <td>-0.589129</td>\n",
       "      <td>1.616877</td>\n",
       "      <td>-0.961010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004921</td>\n",
       "      <td>0.592309</td>\n",
       "      <td>-1.217791</td>\n",
       "      <td>-0.779120</td>\n",
       "      <td>0.815189</td>\n",
       "      <td>-0.300531</td>\n",
       "      <td>0.240677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.122941</td>\n",
       "      <td>0.333826</td>\n",
       "      <td>-0.083531</td>\n",
       "      <td>-0.085607</td>\n",
       "      <td>1.041494</td>\n",
       "      <td>1.124528</td>\n",
       "      <td>1.176074</td>\n",
       "      <td>0.025734</td>\n",
       "      <td>-0.129343</td>\n",
       "      <td>-0.435462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247903</td>\n",
       "      <td>0.946195</td>\n",
       "      <td>-0.367519</td>\n",
       "      <td>0.633486</td>\n",
       "      <td>0.268009</td>\n",
       "      <td>0.680456</td>\n",
       "      <td>1.363238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.440540</td>\n",
       "      <td>-0.381134</td>\n",
       "      <td>-0.318574</td>\n",
       "      <td>0.613498</td>\n",
       "      <td>1.257364</td>\n",
       "      <td>-0.382675</td>\n",
       "      <td>-0.310298</td>\n",
       "      <td>0.509424</td>\n",
       "      <td>-0.039889</td>\n",
       "      <td>-1.386820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095711</td>\n",
       "      <td>2.051557</td>\n",
       "      <td>-0.605160</td>\n",
       "      <td>0.373638</td>\n",
       "      <td>-0.413178</td>\n",
       "      <td>1.078297</td>\n",
       "      <td>0.259838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.782702</td>\n",
       "      <td>0.336739</td>\n",
       "      <td>-0.357267</td>\n",
       "      <td>2.255564</td>\n",
       "      <td>0.791485</td>\n",
       "      <td>0.601925</td>\n",
       "      <td>0.569214</td>\n",
       "      <td>-0.444142</td>\n",
       "      <td>-0.574265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606285</td>\n",
       "      <td>1.296535</td>\n",
       "      <td>-1.192561</td>\n",
       "      <td>0.905022</td>\n",
       "      <td>-0.285185</td>\n",
       "      <td>1.044787</td>\n",
       "      <td>0.764147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>-0.458468</td>\n",
       "      <td>0.341188</td>\n",
       "      <td>-0.527984</td>\n",
       "      <td>0.101789</td>\n",
       "      <td>1.421188</td>\n",
       "      <td>-0.190172</td>\n",
       "      <td>0.497105</td>\n",
       "      <td>0.461110</td>\n",
       "      <td>0.129927</td>\n",
       "      <td>-0.255010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.931559</td>\n",
       "      <td>0.913477</td>\n",
       "      <td>-1.026275</td>\n",
       "      <td>0.940874</td>\n",
       "      <td>-0.458415</td>\n",
       "      <td>0.756727</td>\n",
       "      <td>0.651880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>0.232102</td>\n",
       "      <td>-0.302728</td>\n",
       "      <td>0.415673</td>\n",
       "      <td>0.349968</td>\n",
       "      <td>0.224248</td>\n",
       "      <td>1.327219</td>\n",
       "      <td>0.246681</td>\n",
       "      <td>1.134674</td>\n",
       "      <td>-0.501171</td>\n",
       "      <td>-0.069691</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399264</td>\n",
       "      <td>0.775659</td>\n",
       "      <td>-0.432012</td>\n",
       "      <td>1.352493</td>\n",
       "      <td>-0.021824</td>\n",
       "      <td>1.243398</td>\n",
       "      <td>0.247189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>0.222461</td>\n",
       "      <td>0.263529</td>\n",
       "      <td>-0.219165</td>\n",
       "      <td>-0.681437</td>\n",
       "      <td>2.198796</td>\n",
       "      <td>0.343512</td>\n",
       "      <td>-0.008500</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.776262</td>\n",
       "      <td>-0.926901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036101</td>\n",
       "      <td>1.799631</td>\n",
       "      <td>-0.755566</td>\n",
       "      <td>0.644902</td>\n",
       "      <td>0.644837</td>\n",
       "      <td>1.018173</td>\n",
       "      <td>1.226416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>0.279918</td>\n",
       "      <td>0.469145</td>\n",
       "      <td>0.088338</td>\n",
       "      <td>-0.141629</td>\n",
       "      <td>1.697001</td>\n",
       "      <td>0.686947</td>\n",
       "      <td>0.939171</td>\n",
       "      <td>0.773699</td>\n",
       "      <td>-0.330680</td>\n",
       "      <td>-0.377207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481366</td>\n",
       "      <td>1.069993</td>\n",
       "      <td>-1.049818</td>\n",
       "      <td>0.431583</td>\n",
       "      <td>0.369757</td>\n",
       "      <td>0.626306</td>\n",
       "      <td>0.348555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows Ã— 2051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -1.128828 -0.016527 -0.235906  0.698256  0.543091 -0.188442 -1.163451   \n",
       "1    -1.018054  0.201727 -0.318205  0.681947  0.933839 -1.113128 -0.237611   \n",
       "2    -0.818614 -0.363673 -0.230043 -0.020318  1.628263 -1.709915  0.289006   \n",
       "3    -0.122941  0.333826 -0.083531 -0.085607  1.041494  1.124528  1.176074   \n",
       "4    -0.440540 -0.381134 -0.318574  0.613498  1.257364 -0.382675 -0.310298   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8755 -0.428815  0.782702  0.336739 -0.357267  2.255564  0.791485  0.601925   \n",
       "8756 -0.458468  0.341188 -0.527984  0.101789  1.421188 -0.190172  0.497105   \n",
       "8757  0.232102 -0.302728  0.415673  0.349968  0.224248  1.327219  0.246681   \n",
       "8758  0.222461  0.263529 -0.219165 -0.681437  2.198796  0.343512 -0.008500   \n",
       "8759  0.279918  0.469145  0.088338 -0.141629  1.697001  0.686947  0.939171   \n",
       "\n",
       "             7         8         9  ...      2041      2042      2043  \\\n",
       "0     0.662182  0.054379 -0.649465  ... -0.626992  1.508141 -0.575721   \n",
       "1    -0.608168  0.940666 -0.139904  ...  0.670192  0.204470 -0.488212   \n",
       "2    -0.589129  1.616877 -0.961010  ...  1.004921  0.592309 -1.217791   \n",
       "3     0.025734 -0.129343 -0.435462  ... -0.247903  0.946195 -0.367519   \n",
       "4     0.509424 -0.039889 -1.386820  ... -0.095711  2.051557 -0.605160   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "8755  0.569214 -0.444142 -0.574265  ... -0.606285  1.296535 -1.192561   \n",
       "8756  0.461110  0.129927 -0.255010  ... -0.931559  0.913477 -1.026275   \n",
       "8757  1.134674 -0.501171 -0.069691  ... -0.399264  0.775659 -0.432012   \n",
       "8758  0.647222  0.776262 -0.926901  ...  0.036101  1.799631 -0.755566   \n",
       "8759  0.773699 -0.330680 -0.377207  ...  0.481366  1.069993 -1.049818   \n",
       "\n",
       "          2044      2045      2046      2047  diaper_change  feeding  patting  \n",
       "0     0.488262  0.645725 -0.073558  0.912954            1.0      0.0      0.0  \n",
       "1    -0.334271  0.508915  0.046070  0.630174            1.0      0.0      0.0  \n",
       "2    -0.779120  0.815189 -0.300531  0.240677            1.0      0.0      0.0  \n",
       "3     0.633486  0.268009  0.680456  1.363238            1.0      0.0      0.0  \n",
       "4     0.373638 -0.413178  1.078297  0.259838            1.0      0.0      0.0  \n",
       "...        ...       ...       ...       ...            ...      ...      ...  \n",
       "8755  0.905022 -0.285185  1.044787  0.764147            0.0      0.0      1.0  \n",
       "8756  0.940874 -0.458415  0.756727  0.651880            0.0      0.0      1.0  \n",
       "8757  1.352493 -0.021824  1.243398  0.247189            0.0      0.0      1.0  \n",
       "8758  0.644902  0.644837  1.018173  1.226416            0.0      0.0      1.0  \n",
       "8759  0.431583  0.369757  0.626306  0.348555            0.0      0.0      1.0  \n",
       "\n",
       "[8760 rows x 2051 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels1 = X[['diaper_change','feeding','patting']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels1 = X_val[['diaper_change','feeding','patting']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "for i in range(0,len(train_labels1),seq):\n",
    "#print(i)\n",
    "    train_labels1 = np.array(train_labels1)\n",
    "    y1 = train_labels1[i:i+seq]\n",
    "    train_labels.append(y1[-1])\n",
    "\n",
    "validation_labels = []\n",
    "for i in range(0,len(validation_labels1),seq):\n",
    "#print(i)\n",
    "    validation_labels1 = np.array(validation_labels1)\n",
    "    y2 = validation_labels1[i:i+seq]\n",
    "    validation_labels.append(y2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = []\n",
    "for i in range(0,len(validation_labels1),seq):\n",
    "#print(i)\n",
    "    validation_labels1 = np.array(validation_labels1)\n",
    "    y2 = validation_labels1[i:i+seq]\n",
    "    validation_labels.append(y2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.drop(['diaper_change','feeding','patting'],axis=1,inplace=True)\n",
    "X_val.drop(['diaper_change','feeding','patting'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array(X)\n",
    "#X = X.reshape(-1,seq,X.shape[1])\n",
    "X_val = np.array(X_val)\n",
    "X_val = X_val.reshape(-1,seq,X_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_labels = np.array(train_labels)\n",
    "validation_labels = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 255 samples, validate on 64 samples\n",
      "Epoch 1/40\n",
      "255/255 [==============================] - 6s 23ms/step - loss: 1.0773 - accuracy: 0.5765 - val_loss: 0.8376 - val_accuracy: 0.3281\n",
      "Epoch 2/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.6543 - accuracy: 0.6824 - val_loss: 0.1528 - val_accuracy: 0.9688\n",
      "Epoch 3/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.4337 - accuracy: 0.8784 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 4/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.3693 - accuracy: 0.9020 - val_loss: 0.1122 - val_accuracy: 1.0000\n",
      "Epoch 5/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.3073 - accuracy: 0.9020 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
      "Epoch 6/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.2370 - accuracy: 0.9216 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
      "Epoch 7/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.2077 - accuracy: 0.9451 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
      "Epoch 8/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.1603 - accuracy: 0.9490 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 9/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.1401 - accuracy: 0.9608 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 10/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.1203 - accuracy: 0.9686 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 11/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.1078 - accuracy: 0.9686 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 12/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0893 - accuracy: 0.9765 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 13/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0710 - accuracy: 0.9765 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 14/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0569 - accuracy: 0.9804 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 15/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0463 - accuracy: 0.9882 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 16/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0431 - accuracy: 0.9882 - val_loss: 0.0706 - val_accuracy: 0.9688\n",
      "Epoch 17/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 18/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 19/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0199 - accuracy: 0.9882 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 20/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 21/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9844\n",
      "Epoch 22/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9844\n",
      "Epoch 23/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9844\n",
      "Epoch 24/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9844\n",
      "Epoch 25/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 26/40\n",
      "255/255 [==============================] - 5s 19ms/step - loss: 8.1340e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff10c6ef9b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,train_labels,batch_size=120,epochs=40,validation_split=0.2,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in answer:\n",
    "    y_pred.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1. 0. 0.]\n",
      "120 [1. 0. 0.]\n",
      "240 [1. 0. 0.]\n",
      "360 [1. 0. 0.]\n",
      "480 [1. 0. 0.]\n",
      "600 [1. 0. 0.]\n",
      "720 [1. 0. 0.]\n",
      "840 [1. 0. 0.]\n",
      "960 [0. 1. 0.]\n",
      "1080 [0. 1. 0.]\n",
      "1200 [0. 1. 0.]\n",
      "1320 [0. 1. 0.]\n",
      "1440 [0. 1. 0.]\n",
      "1560 [0. 1. 0.]\n",
      "1680 [0. 1. 0.]\n",
      "1800 [0. 1. 0.]\n",
      "1920 [0. 1. 0.]\n",
      "2040 [0. 1. 0.]\n",
      "2160 [0. 1. 0.]\n",
      "2280 [0. 1. 0.]\n",
      "2400 [0. 1. 0.]\n",
      "2520 [0. 1. 0.]\n",
      "2640 [0. 1. 0.]\n",
      "2760 [0. 1. 0.]\n",
      "2880 [0. 0. 1.]\n",
      "3000 [0. 0. 1.]\n",
      "3120 [0. 0. 1.]\n",
      "3240 [0. 0. 1.]\n",
      "3360 [0. 0. 1.]\n",
      "3480 [0. 0. 1.]\n",
      "3600 [0. 0. 1.]\n",
      "3720 [0. 0. 1.]\n",
      "3840 [0. 0. 1.]\n",
      "3960 [0. 0. 1.]\n",
      "4080 [0. 0. 1.]\n",
      "4200 [0. 0. 1.]\n",
      "4320 [0. 0. 1.]\n",
      "4440 [0. 0. 1.]\n",
      "4560 [0. 0. 1.]\n",
      "4680 [0. 0. 1.]\n",
      "4800 [0. 0. 1.]\n",
      "4920 [0. 0. 1.]\n",
      "5040 [0. 0. 1.]\n",
      "5160 [1. 0. 0.]\n",
      "5280 [1. 0. 0.]\n",
      "5400 [0. 0. 1.]\n",
      "5520 [0. 0. 1.]\n",
      "5640 [1. 0. 0.]\n",
      "5760 [1. 0. 0.]\n",
      "5880 [1. 0. 0.]\n",
      "6000 [1. 0. 0.]\n",
      "6120 [0. 0. 1.]\n",
      "6240 [0. 0. 1.]\n",
      "6360 [0. 0. 1.]\n",
      "6480 [0. 0. 1.]\n",
      "6600 [0. 0. 1.]\n",
      "6720 [0. 0. 1.]\n",
      "6840 [0. 0. 1.]\n",
      "6960 [0. 0. 1.]\n",
      "7080 [0. 0. 1.]\n",
      "7200 [0. 0. 1.]\n",
      "7320 [0. 0. 1.]\n",
      "7440 [0. 0. 1.]\n",
      "7560 [0. 0. 1.]\n",
      "7680 [0. 0. 1.]\n",
      "7800 [0. 0. 1.]\n",
      "7920 [0. 0. 1.]\n",
      "8040 [0. 0. 1.]\n",
      "8160 [0. 0. 1.]\n",
      "8280 [0. 0. 1.]\n",
      "8400 [0. 0. 1.]\n",
      "8520 [0. 0. 1.]\n",
      "8640 [0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(validation_labels1),seq):\n",
    "    validation_labels1 = np.array(validation_labels1)\n",
    "    y2 = validation_labels1[i:i+seq]\n",
    "    print(i,y2[-1])\n",
    "    test.append(y2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tp = []\n",
    "for i in test:\n",
    "    y_tp.append(np.argmax(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.14      0.21        14\n",
      "           1       0.48      0.81      0.60        16\n",
      "           2       0.93      0.88      0.90        43\n",
      "\n",
      "    accuracy                           0.73        73\n",
      "   macro avg       0.60      0.61      0.57        73\n",
      "weighted avg       0.73      0.73      0.71        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_tp,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2 12  0]\n",
      " [ 0 13  3]\n",
      " [ 3  2 38]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_tp,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
